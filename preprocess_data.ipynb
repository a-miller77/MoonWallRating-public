{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "623cca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from preprocessing import *\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "84cb3755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sampling(dataframe):\n",
    "    over_bench_mult = 2.2;\n",
    "    under_bench_mult = 1.5;\n",
    "\n",
    "    smp2 = dataframe[dataframe.Grade == 2]\n",
    "    smp3 = dataframe[dataframe.Grade == 3]\n",
    "    smp4 = dataframe[dataframe.Grade == 4]\n",
    "    smp5 = dataframe[dataframe.Grade == 5]\n",
    "    smp6 = dataframe[dataframe.Grade == 6]\n",
    "    smp7 = dataframe[dataframe.Grade == 7]\n",
    "    smp8 = dataframe[dataframe.Grade == 8]\n",
    "    smp9 = dataframe[dataframe.Grade == 9]\n",
    "    smp10 = dataframe[dataframe.Grade == 10]\n",
    "\n",
    "    under_3 = pd.concat([smp3[smp3.IsBenchmark != True].sample(frac=.73), \n",
    "                     smp3[smp3.IsBenchmark == True].sample(frac=under_bench_mult, replace=True)])\n",
    "    under_5 = pd.concat([smp5[smp5.IsBenchmark != True].sample(frac=.77), \n",
    "                     smp5[smp5.IsBenchmark == True].sample(frac=under_bench_mult, replace=True)])\n",
    "\n",
    "    over_2 = smp2.sample(frac=2, replace=True)\n",
    "    over_4 = pd.concat([smp4.sample(frac=1.4, replace=True), \n",
    "                    smp4[smp4.IsBenchmark == True].sample(frac=over_bench_mult, replace=True)])\n",
    "    over_6 = pd.concat([smp6.sample(frac=1.2, replace=True), \n",
    "                    smp6[smp6.IsBenchmark == True].sample(frac=over_bench_mult, replace=True)])\n",
    "    over_7 = pd.concat([smp7.sample(frac=1.5, replace=True), \n",
    "                    smp7[smp7.IsBenchmark == True].sample(frac=over_bench_mult, replace=True)])\n",
    "    over_8 = pd.concat([smp8.sample(frac=1.3, replace=True), \n",
    "                    smp8[smp8.IsBenchmark == True].sample(frac=over_bench_mult, replace=True)])\n",
    "    over_9 = pd.concat([smp9.sample(frac=2.1, replace=True), \n",
    "                    smp9[smp9.IsBenchmark == True].sample(frac=over_bench_mult, replace=True)])\n",
    "    over_10 = smp10.sample(frac=3.5, replace=True)\n",
    "\n",
    "    return pd.concat([over_2, under_3, over_4, under_5, over_6, over_7, over_8, over_9, over_10])\n",
    "\n",
    "def sample_train_test_val_df(X_train, X_test, X_val):\n",
    "    return data_sampling(X_train), data_sampling(X_test), data_sampling(X_val)\n",
    "\n",
    "def showcase_sampled_train_split(dataframe=routeImport.copy()):\n",
    "    sns.countplot(x='Grade', data=data_sampling(dataframe.sample(frac=0.8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dd0c3983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_val(df, train_size, test_size, val_size):\n",
    "    X = df\n",
    "    y = df.Grade.to_numpy()-df.Grade.min()\n",
    "\n",
    "    # train is now 80% of the entire data set, test is now 20% of the dataset\n",
    "    # X_train and X_test are DataFrames of routes, y_train and y_test are numpy arrays of grades\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size, stratify=y)\n",
    "    \n",
    "    # test is now 10% of the initial data set\n",
    "    # validation is now 10% of the initial data set\n",
    "    # X_val and X_test are DataFrames of routes, y_val and y_test are numpy arrays of grades\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=(test_size / (test_size + val_size)), stratify=y_test) \n",
    "    \n",
    "    print(\"X train, test, val (before sampling): \", len(X_train), len(X_val), len(X_test))\n",
    "    print(\"y train, test, val (before sampling): \", len(y_train), len(y_val), len(y_test))\n",
    "    \n",
    "    # over and undersample the datasets without bleed between train, test, and validation sets\n",
    "    X_train, X_test, X_val = sample_train_test_val_df(X_train, X_test, X_val)\n",
    "    # NOTE: the oversamping method appears to cause the datasets to be slightly different sizes each time\n",
    "    # this is assumed to be due to the stratification\n",
    "    \n",
    "    print(\"X train, test, val (after sampling): \", len(X_train), len(X_val), len(X_test))\n",
    "    print(\"y train, test, val (after sampling): \", len(y_train), len(y_val), len(y_test))\n",
    "    \n",
    "    tr_y = X_train.Grade.to_numpy()-2\n",
    "    tst_y = X_test.Grade.to_numpy()-2\n",
    "    vl_y = X_val.Grade.to_numpy()-2\n",
    "    \n",
    "    X_train, t, y_train, t = train_test_split(X_train, tr_y, test_size=0.0005, stratify=tr_y)\n",
    "    X_test, t, y_test, t = train_test_split(X_test, tst_y, test_size=0.005, stratify=tst_y) \n",
    "    X_val, t, y_val, t = train_test_split(X_val, vl_y, test_size=0.005, stratify=vl_y) \n",
    "    \n",
    "    print(\"X train, test, val (after fixing): \", len(X_train), len(X_val), len(X_test))\n",
    "    print(\"y train, test, val (after fixing): \", len(y_train), len(y_val), len(y_test))\n",
    "    \n",
    "    return (np.array(X_train.TokenizedSequence.to_list()), \n",
    "            np.array(X_test.TokenizedSequence.to_list()), \n",
    "            np.array(X_val.TokenizedSequence.to_list()), \n",
    "            y_train, y_test, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dc536473",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('./data/route_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "782357ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(11, 15):\n",
    "    df = df[df.Grade != i]\n",
    "df = df[df.MoonBoardHoldSetup == 'MoonBoard Masters 2017']\n",
    "df = df[df.RepeatText != 'Be the first to repeat this problem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aaa0c230",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_sequences = df.apply(generate_route_sequence, axis=1)\n",
    "df['TokenizedSequence'] = route_sequences.map(tokenize_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "92bef689",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "test_size = 0.1\n",
    "val_size = 0.1\n",
    "assert train_size + test_size + val_size == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bbf39d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train, test, val (before sampling):  17356 2169 2170\n",
      "y train, test, val (before sampling):  17356 2169 2170\n",
      "X train, test, val (after sampling):  19052 2383 2393\n",
      "y train, test, val (after sampling):  17356 2169 2170\n",
      "X train, test, val (after fixing):  19042 2371 2381\n",
      "y train, test, val (after fixing):  19042 2371 2381\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, X_val, y_train, y_test, y_val = split_train_test_val(df, train_size, test_size, val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "eb0535b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {'X': X_train, 'y': y_train}\n",
    "test_data = {'X': X_test, 'y': y_test}\n",
    "val_data = {'X': X_val, 'y': y_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9e419e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, split in zip([train_data, test_data, val_data], ['train', 'test', 'val']):\n",
    "    with open(f'./data/{split}_preprocessed_routes', 'wb') as f:\n",
    "        pickle.dump(data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
